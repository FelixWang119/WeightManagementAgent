"""
Agent å®ç°ï¼ˆå·¥å…·è°ƒç”¨ç‰ˆï¼‰

æ”¯æŒè‡ªç„¶è¯­è¨€è®°å½•å’Œå¯Œåª’ä½“æ¶ˆæ¯è¿”å›
"""

from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import json

from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from langchain_core.tools import tool

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from services.langchain.base import get_chat_model
from services.langchain.memory import WeightManagementMemory
from services.langchain.tools import create_tools_for_user, execute_tool
from services.user_profile_service import UserProfileService
from config.settings import fastapi_settings


class SimpleAgent:
    """
    Simple Agent for Weight Management

    æ”¯æŒå·¥å…·è°ƒç”¨çš„Agentï¼Œå¯ä»¥ï¼š
    1. è¯†åˆ«è‡ªç„¶è¯­è¨€æ„å›¾å¹¶è‡ªåŠ¨è®°å½•æ•°æ®
    2. è¿”å›ç»“æ„åŒ–æ¶ˆæ¯ï¼ˆæ”¯æŒå¯Œåª’ä½“ï¼‰
    """

    def __init__(
        self,
        user_id: int,
        db: AsyncSession,
        agent_name: Optional[str] = None,
        personality_type: Optional[str] = "warm",
        enable_memory: bool = True,
        history_injection_rounds: int = 5,
        enable_midterm_memory: bool = True,
        debug: Optional[bool] = None
    ):
        self.user_id = user_id
        self.db = db
        self.agent_name = agent_name or "å°åŠ©"
        self.personality_type = personality_type
        self.enable_memory = enable_memory
        self.history_injection_rounds = history_injection_rounds
        self.enable_midterm_memory = enable_midterm_memory
        self.DEBUG = debug if debug is not None else fastapi_settings.DEBUG

        self.llm = get_chat_model()
        self.tool_definitions = create_tools_for_user(db, user_id)
        self.tools = self._create_langchain_tools()

        # ç”¨æˆ·ç”»åƒæ•°æ®ï¼ˆå¸¦TTLç¼“å­˜ï¼‰
        self.user_profile_data: Optional[Dict[str, Any]] = None
        self._profile_loaded: bool = False
        self._profile_loaded_at: Optional[datetime] = None
        self._profile_cache_ttl: timedelta = timedelta(minutes=10)  # 10åˆ†é’Ÿç¼“å­˜

        if enable_memory:
            self.memory = WeightManagementMemory(
                user_id=user_id,
                short_term_limit=200
            )
        else:
            self.memory = None
    
    def _create_langchain_tools(self):
        """Convert custom tool definitions to LangChain Tool objects"""
        from langchain_core.tools import Tool
        
        tools = []
        for tool_def in self.tool_definitions:
            # Create a closure to capture the tool_name
            def make_tool_func(tool_name):
                async def tool_func(**kwargs):
                    from services.langchain.tools import execute_tool
                    return await execute_tool(tool_name, kwargs, self.user_id, self.db)
                return tool_func
            
            tool = Tool(
                name=tool_def["name"],
                description=tool_def["description"],
                func=make_tool_func(tool_def["name"]),
                args_schema=None,  # We'll handle validation in execute_tool
            )
            tools.append(tool)
        
        return tools
    
    async def load_user_profile(self) -> Dict[str, Any]:
        """
        æ‡’åŠ è½½ç”¨æˆ·ç”»åƒæ•°æ®
        
        ä½¿ç”¨ UserProfileService è·å–å¸¦ç¼“å­˜çš„æ•°æ®
        """
        if not self._profile_loaded:
            try:
                self.user_profile_data = await UserProfileService.get_complete_profile(
                    self.user_id, self.db
                )
                # æ›´æ–°agent_nameå’Œpersonality_typeï¼ˆå¦‚æœä»æ•°æ®åº“è·å–åˆ°ï¼‰
                if self.user_profile_data:
                    self.agent_name = self.user_profile_data.get("agent_name", self.agent_name)
                    self.personality_type = self.user_profile_data.get("personality_type", self.personality_type)
                self._profile_loaded = True
            except Exception as e:
                print(f"åŠ è½½ç”¨æˆ·ç”»åƒå¤±è´¥: {e}")
                # è¿”å›ç©ºæ•°æ®ï¼Œä¸å½±å“ä¸»æµç¨‹
                self.user_profile_data = {
                    "user_id": self.user_id,
                    "agent_name": self.agent_name,
                    "personality_type": self.personality_type,
                    "basic_info": {},
                    "profile_desc": {},
                    "style_addition": ""
                }
                self._profile_loaded = True
        
        return self.user_profile_data or {}

    async def _build_system_prompt(self, conversation_context: str = "", user_message: str = "") -> str:
        """
        æ„å»ºå®Œæ•´çš„ç³»ç»Ÿæç¤ºï¼ˆç”¨æˆ·ç”»åƒ + è¯¦ç»†é£æ ¼ + å¯¹è¯ä¸Šä¸‹æ–‡ + ä¸­æœŸè®°å¿†ï¼‰

        Args:
            conversation_context: å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå†…å­˜æ³¨å…¥ï¼‰
            user_message: å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼ˆç”¨äºæ£€ç´¢ä¸­æœŸè®°å¿†ï¼‰

        Returns:
            å®Œæ•´çš„ç³»ç»Ÿæç¤ºå­—ç¬¦ä¸²
        """
        # 1. åŠ è½½ç”¨æˆ·ç”»åƒæ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰
        profile_data = await self.load_user_profile()

        # 2. å¦‚æœå¯ç”¨ä¸­æœŸè®°å¿†ï¼Œä»å‘é‡åº“æ£€ç´¢ç›¸å…³å†å²è®°å¿†
        memory_context = ""
        if self.enable_midterm_memory and self.memory and user_message:
            try:
                relevant_memories = await self.memory.search_memory(user_message, k=3)
                if relevant_memories:
                    memory_lines = []
                    for mem in relevant_memories:
                        content = mem.get('content', '')[:100]  # é™åˆ¶é•¿åº¦
                        memory_lines.append(f"- {content}")
                    memory_context = "\nã€ç›¸å…³å†å²è®°å¿†ã€‘\n" + "\n".join(memory_lines) + "\n"
            except Exception as e:
                print(f"æ£€ç´¢ä¸­æœŸè®°å¿†å¤±è´¥: {e}")
                # ä¸­æœŸè®°å¿†æ£€ç´¢å¤±è´¥ä¸å½±å“ä¸»æµç¨‹

        # 3. ç»„åˆå¯¹è¯ä¸Šä¸‹æ–‡å’Œä¸­æœŸè®°å¿†
        full_context = conversation_context + memory_context

        # 4. ä½¿ç”¨ UserProfileService æ ¼å¼åŒ–ç³»ç»Ÿæç¤º
        # æ³¨æ„ï¼šUserProfileService.format_system_prompt å·²ç»åŒ…å«äº†ï¼š
        # - ç”¨æˆ·åŸºç¡€ä¿¡æ¯
        # - ç”¨æˆ·ç”»åƒï¼ˆé—®å·å›ç­”åˆ†ç±»ï¼‰
        # - è¯¦ç»†é£æ ¼é…ç½®ï¼ˆä» assistant_styles.pyï¼‰
        # - å½“å‰æ—¶é—´
        # - å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆä¼ å…¥çš„ full_contextï¼‰
        # - é€šç”¨å›å¤æ ¼å¼
        return await UserProfileService.format_system_prompt(profile_data, full_context)

    def _build_conversation_context(self, chat_history: List[Dict[str, str]]) -> str:
        """æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²

        Args:
            chat_history: å¯¹è¯å†å²åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« 'role' å’Œ 'content'

        Returns:
            æ ¼å¼åŒ–åçš„å¯¹è¯ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        if not chat_history:
            return ""

        # åªå–æœ€è¿‘ N è½®å¯¹è¯ï¼ˆæ¯è½®åŒ…å«ç”¨æˆ·æ¶ˆæ¯å’ŒåŠ©æ‰‹æ¶ˆæ¯ï¼‰
        # history_injection_rounds æ§åˆ¶æ³¨å…¥å¤šå°‘è½®å®Œæ•´å¯¹è¯
        recent_history = chat_history[-(self.history_injection_rounds * 2):]

        formatted_messages = []
        for i, msg in enumerate(recent_history):
            role = msg.get("role", "")
            content = msg.get("content", "")

            # è½¬æ¢ä¸ºä¸­æ–‡è§’è‰²æ ‡ç­¾
            if role == "user":
                role_label = "ç”¨æˆ·"
            elif role == "assistant":
                role_label = "åŠ©æ‰‹"
            else:
                role_label = role

            # å¯¹äºæœ€å1è½®å¯¹è¯ï¼ˆæœ€è¿‘çš„ç”¨æˆ·+åŠ©æ‰‹æ¶ˆæ¯ï¼‰ï¼Œä¿ç•™å®Œæ•´å†…å®¹
            # å¯¹äºè¾ƒæ—©çš„å¯¹è¯ï¼Œæˆªæ–­åˆ°100å­—ç¬¦ä»¥èŠ‚çœ token
            is_last_two_messages = i >= len(recent_history) - 2
            if not is_last_two_messages and len(content) > 100:
                content = content[:100] + "..."

            formatted_messages.append(f"{role_label}: {content}")

        return "\n".join(formatted_messages)

    async def chat(self, message: str) -> Dict[str, Any]:
        """å¯¹è¯å…¥å£ - æ”¯æŒå·¥å…·è°ƒç”¨å’Œå¤šè½®å¯¹è¯"""
        try:
            conversation_context = ""
            chat_history = []
            if self.memory:
                await self.memory.load_context()
                chat_history = self.memory.get_chat_history()
                conversation_context = self._build_conversation_context(chat_history)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç»§ç»­ä¸Šä¸€è½®å¯¹è¯çš„å·¥å…·è°ƒç”¨
            pending_tool_call = await self._check_pending_tool_call(message, chat_history)

            if pending_tool_call:
                # æ‰§è¡Œä¸Šä¸€è½®å¯¹è¯ä¸­æœªå®Œæˆçš„å·¥å…·è°ƒç”¨
                return await self._handle_pending_tool_call(pending_tool_call, message)

            # æ„å»ºç³»ç»Ÿæç¤ºï¼ˆåŒ…å«å·¥å…·è¯´æ˜ï¼‰
            system_prompt = await self._build_system_prompt_with_tools(conversation_context, message)

            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [{"role": "system", "content": system_prompt}]

            # æ·»åŠ å†å²å¯¹è¯ï¼ˆä½œä¸º user/assistant æ¶ˆæ¯ï¼Œè€Œä¸æ˜¯ system promptï¼‰
            if chat_history:
                # åªå–æœ€è¿‘ N è½®å¯¹è¯ï¼ˆç”± history_injection_rounds æ§åˆ¶ï¼‰
                # æ³¨æ„ï¼šä¸è¦åŒ…å«å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼Œå› ä¸ºå®ƒä¼šè¢«å•ç‹¬æ·»åŠ 
                recent_history = chat_history[-(self.history_injection_rounds * 2):]
                
                # å¢å¼ºå¯¹ç®€çŸ­å›ç­”çš„ç†è§£ï¼šå½“ç”¨æˆ·ç®€çŸ­å›ç­”æ—¶ï¼Œä¸»åŠ¨æé†’AIæ³¨æ„ä¸Šä¸‹æ–‡
                if message.strip() in ["éœ€è¦", "æ˜¯çš„", "å¥½çš„", "å¯¹", "å¯ä»¥", "è¦", "è¡Œ"]:
                    # æ£€æŸ¥æœ€è¿‘çš„åŠ©æ‰‹æ¶ˆæ¯æ˜¯å¦åŒ…å«è¯¢é—®å¥
                    last_assistant_msg = ""
                    for msg in reversed(recent_history):
                        if msg.get("role") == "assistant":
                            last_assistant_msg = msg.get("content", "")
                            break
                    
                    # å¦‚æœåŠ©æ‰‹æœ€è¿‘è¯¢é—®äº†"éœ€è¦åˆ¶å®šè®¡åˆ’å—ï¼Ÿ"ï¼Œé‚£ä¹ˆ"éœ€è¦"å°±æ˜¯è‚¯å®šå›ç­”
                    if "éœ€è¦æˆ‘" in last_assistant_msg and "å—ï¼Ÿ" in last_assistant_msg:
                        system_prompt += "\n\nã€é‡è¦æç¤ºã€‘ç”¨æˆ·åˆšåˆšç»™å‡ºäº†ç®€çŸ­çš„è‚¯å®šå›ç­”'éœ€è¦'ï¼Œè¿™æ˜¯åœ¨ç¡®è®¤æ‚¨åˆšæ‰çš„æè®®'éœ€è¦æˆ‘å¸®æ‚¨åˆ¶å®šå…·ä½“çš„è¿åŠ¨è®¡åˆ’å—ï¼Ÿ'ã€‚è¯·ç›´æ¥å¼€å§‹åˆ¶å®šè®¡åˆ’ï¼Œæ— éœ€å†æ¬¡ç¡®è®¤ã€‚"
                    else:
                        system_prompt += "\n\nã€é‡è¦æç¤ºã€‘ç”¨æˆ·åˆšåˆšç»™å‡ºäº†ç®€çŸ­çš„è‚¯å®šå›ç­”ï¼Œè¯·ç»“åˆæœ€è¿‘çš„å¯¹è¯å†å²ï¼Œç†è§£ç”¨æˆ·æ˜¯åœ¨ç¡®è®¤ä¹‹å‰çš„æè®®ã€‚"
                    
                for msg in recent_history:
                    role = msg.get("role", "")
                    content = msg.get("content", "")
                    # è½¬æ¢ä¸º OpenAI æ ¼å¼çš„è§’è‰²åç§°
                    if role == "user":
                        messages.append({"role": "user", "content": content})
                    elif role == "assistant":
                        messages.append({"role": "assistant", "content": content})

            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages.append({"role": "user", "content": message})

            # è°ƒè¯•ï¼šåªåœ¨ç‰¹å®šæƒ…å†µä¸‹æ‰“å°æ¶ˆæ¯ç»“æ„
            if self.DEBUG and message.strip() in ["éœ€è¦", "æ˜¯çš„", "å¥½çš„", "å¯¹", "å¯ä»¥"]:
                print(f"[DEBUG] ä¼ é€’ç»™ AI çš„æ¶ˆæ¯æ•°é‡: {len(messages)}")
                print(f"[DEBUG] å†å²å¯¹è¯æ¶ˆæ¯: {len(messages) - 2} æ¡ï¼ˆsystem + å½“å‰æ¶ˆæ¯é™¤å¤–ï¼‰")
                for i, msg in enumerate(messages):
                    role = msg.get("role", "")
                    content_preview = msg.get("content", "")[:80]
                    print(f"[DEBUG]   {i+1}. {role}: {content_preview}...")

            # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šè®©AIå†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·
            response = await self.llm.ainvoke(messages)
            ai_content = response.content if hasattr(response, 'content') else str(response)
            
            if self.DEBUG:
                print(f"[DEBUG] AIåŸå§‹å“åº”: {ai_content[:500]}...")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·ï¼ˆé€šè¿‡è§£æAIè¿”å›çš„JSONï¼‰
            tool_calls = self._parse_tool_calls(ai_content)
            
            if self.DEBUG:
                print(f"[DEBUG] AIå†…å®¹: {ai_content[:500]}...")
                print(f"[DEBUG] è§£æåˆ°çš„å·¥å…·è°ƒç”¨: {tool_calls}")
            
            if tool_calls:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´å¤šä¿¡æ¯ï¼ˆå¦‚é¥®å“ç±»å‹ï¼‰
                if await self._need_more_info_for_tool_call(tool_calls[0], ai_content):
                    # ä¿å­˜AIçš„é—®é¢˜åˆ°è®°å¿†
                    if self.memory:
                        await self.memory.save_message("user", message)
                        await self.memory.save_message("assistant", ai_content)
                    
                    # æ ‡è®°ä¸ºå¾…å¤„ç†å·¥å…·è°ƒç”¨ï¼Œç­‰å¾…ç”¨æˆ·è¡¥å……ä¿¡æ¯
                    await self._mark_pending_tool_call(tool_calls[0], ai_content)
                    return {
                        "response": ai_content,
                        "structured_response": {"type": "text", "content": ai_content, "actions": []},
                        "intermediate_steps": [],
                        "pending_tool_call": True
                    }
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                tool_results = []
                if self.DEBUG:
                    print(f"[DEBUG] å¼€å§‹æ‰§è¡Œ {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
                
                for tool_call in tool_calls:
                    if self.DEBUG:
                        print(f"[DEBUG] æ‰§è¡Œå·¥å…·: {tool_call['name']}, å‚æ•°: {tool_call['arguments']}")
                    
                    result = await execute_tool(
                        tool_call["name"], 
                        tool_call["arguments"], 
                        self.user_id, 
                        self.db
                    )
                    
                    if self.DEBUG:
                        print(f"[DEBUG] å·¥å…·æ‰§è¡Œç»“æœ: {result}")
                    
                    tool_results.append(result)
                
                # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šè®©AIåŸºäºå·¥å…·ç»“æœç”Ÿæˆå›å¤
                tool_context = self._format_tool_results(tool_results)
                messages.append({"role": "assistant", "content": ai_content})
                messages.append({"role": "user", "content": f"å·¥å…·æ‰§è¡Œç»“æœï¼š\n{tool_context}\n\nè¯·åŸºäºä»¥ä¸Šç»“æœï¼Œç”¨å‹å¥½è‡ªç„¶çš„è¯­æ°”å›å¤ç”¨æˆ·ã€‚å¦‚æœæˆåŠŸè®°å½•äº†æ•°æ®ï¼Œè¯·æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·ï¼Œå¹¶å¯æä¾›ç›¸å…³å»ºè®®ã€‚"})
                
                final_response = await self.llm.ainvoke(messages)
                assistant_reply = final_response.content if hasattr(final_response, 'content') else str(final_response)
                
                # æ„å»ºç»“æ„åŒ–å“åº”
                structured_response = self._build_structured_response(assistant_reply, tool_results)
                
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›AIå›å¤
                assistant_reply = ai_content
                structured_response = {
                    "type": "text",
                    "content": assistant_reply,
                    "actions": []
                }

            # ä¿å­˜åˆ°è®°å¿†
            if self.memory:
                if self.DEBUG:
                    print(f"[DEBUG] ä¿å­˜åˆ°è®°å¿† - ç”¨æˆ·æ¶ˆæ¯: {message[:50]}...")
                    print(f"[DEBUG] ä¿å­˜åˆ°è®°å¿† - åŠ©æ‰‹å›å¤: {assistant_reply[:50]}...")
                await self.memory.save_message("user", message)
                await self.memory.save_message("assistant", assistant_reply)

            # æ¸…é™¤å¾…å¤„ç†å·¥å…·è°ƒç”¨æ ‡è®°
            await self._clear_pending_tool_call()

            return {
                "response": assistant_reply,
                "structured_response": structured_response,
                "intermediate_steps": tool_calls if tool_calls else [],
            }

        except Exception as e:
            print(f"Agent Error: {e}")
            import traceback
            traceback.print_exc()

            # å³ä½¿å‡ºé”™ä¹Ÿè¦ä¿å­˜åˆ°è®°å¿†
            if self.memory:
                await self.memory.save_message("user", message)

            simple_response = await self._simple_reply(message)

            # ä¿å­˜åŠ©æ‰‹å›å¤åˆ°è®°å¿†
            if self.memory:
                await self.memory.save_message("assistant", simple_response)

            return {
                "response": simple_response,
                "structured_response": {"type": "text", "content": simple_response, "actions": []},
                "error": str(e),
            }
    
    async def _build_system_prompt_with_tools(self, conversation_context: str = "", user_message: str = "") -> str:
        """æ„å»ºåŒ…å«å·¥å…·è¯´æ˜çš„ç³»ç»Ÿæç¤º"""
        base_prompt = await self._build_system_prompt(conversation_context, user_message)
        
        # æ·»åŠ å·¥å…·ä½¿ç”¨è¯´æ˜ - ä½¿ç”¨ä¼˜åŒ–åçš„æç¤ºè¯
        tools_description = """

ã€å·¥å…·ä½¿ç”¨è¯´æ˜ã€‘
ä½ å¯ä»¥è°ƒç”¨ä»¥ä¸‹å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·è®°å½•æ•°æ®ã€‚å½“ç”¨æˆ·æåˆ°ä½“é‡ã€é¥®é£Ÿã€è¿åŠ¨ã€é¥®æ°´æ—¶ï¼Œè¯·ä½¿ç”¨å¯¹åº”å·¥å…·ï¼š

1. record_weight - è®°å½•ä½“é‡
   ä½¿ç”¨åœºæ™¯ï¼šç”¨æˆ·æåˆ°"ä½“é‡65kg"ã€"ä»Šå¤©ç§°é‡66.5å…¬æ–¤"
   å‚æ•°ï¼š{"weight": 65.5, "note": "å¯é€‰å¤‡æ³¨"}

2. record_meal - è®°å½•é¤é£Ÿ
   ä½¿ç”¨åœºæ™¯ï¼šç”¨æˆ·æåˆ°"åƒäº†ç‰›è‚‰é¢"ã€"æ—©é¤åƒäº†è±†æµ†æ²¹æ¡"
   å‚æ•°ï¼š{"meal_type": "breakfast/lunch/dinner/snack", "food_description": "é£Ÿç‰©æè¿°", "estimated_calories": 400}

3. record_exercise - è®°å½•è¿åŠ¨
   ä½¿ç”¨åœºæ™¯ï¼šç”¨æˆ·æåˆ°"è·‘æ­¥30åˆ†é’Ÿ"ã€"æ¸¸æ³³ä¸€å°æ—¶"
   å‚æ•°ï¼š{"exercise_type": "è¿åŠ¨ç±»å‹", "duration_minutes": 30, "calories_burned": 300}

4. record_water - è®°å½•é¥®æ°´
   ä½¿ç”¨åœºæ™¯ï¼šç”¨æˆ·æåˆ°"å–äº†500mlæ°´"ã€"å–äº†ä¸¤æ¯æ°´"
   å‚æ•°ï¼š{"amount_ml": 500}

5. get_today_data - è·å–ä»Šæ—¥æ•°æ®
   ä½¿ç”¨åœºæ™¯ï¼šç”¨æˆ·é—®"ä»Šå¤©è®°å½•äº†å¤šå°‘"ã€"ä»Šå¤©åƒäº†ä»€ä¹ˆ"

ã€é‡è¦æç¤ºã€‘
ä½ å¿…é¡»ä»¥ JSON æ ¼å¼è¾“å‡ºå·¥å…·è°ƒç”¨ã€‚åˆ†æç”¨æˆ·æ„å›¾åï¼Œå¦‚æœç”¨æˆ·æåˆ°ä½“é‡ã€é¥®é£Ÿã€è¿åŠ¨ã€é¥®æ°´ç›¸å…³çš„å†…å®¹ï¼Œè¯·è°ƒç”¨å¯¹åº”å·¥å…·ã€‚

ã€å·¥å…·è°ƒç”¨æ ¼å¼ã€‘
å¦‚æœéœ€è¦è°ƒç”¨å·¥å…·ï¼Œè¯·ä»¥ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼š
{
  "tool_calls": [
    {
      "name": "å·¥å…·å",
      "args": {
        "å‚æ•°1": "å€¼1",
        "å‚æ•°2": "å€¼2"
      }
    }
  ]
}

ç¤ºä¾‹ï¼š
ç”¨æˆ·è¯´ï¼š"æˆ‘ä»Šå¤©ä½“é‡æ˜¯70.5å…¬æ–¤"
è¾“å‡ºï¼š{"tool_calls": [{"name": "record_weight", "args": {"weight": 70.5, "note": "ä»Šæ—¥ä½“é‡"}}]}

ç”¨æˆ·è¯´ï¼š"æˆ‘æ—©é¤åƒäº†é¢åŒ…å’Œç‰›å¥¶"
è¾“å‡ºï¼š{"tool_calls": [{"name": "record_meal", "args": {"meal_type": "breakfast", "food_description": "é¢åŒ…å’Œç‰›å¥¶", "estimated_calories": 300}}]}

ç”¨æˆ·è¯´ï¼š"æˆ‘ä»Šå¤©å–äº†2000æ¯«å‡æ°´"
è¾“å‡ºï¼š{"tool_calls": [{"name": "record_water", "args": {"amount_ml": 2000}}]}

ã€è¾“å‡ºè§„åˆ™ã€‘
1. åªè¾“å‡º JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—
2. å¦‚æœæ²¡æœ‰éœ€è¦è°ƒç”¨çš„å·¥å…·ï¼Œç›´æ¥æ­£å¸¸å›å¤å³å¯
3. å¦‚æœè°ƒç”¨å·¥å…·ï¼Œå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿° JSON æ ¼å¼
"""
        
        return base_prompt + tools_description
    
    def _parse_tool_calls(self, content: str) -> List[Dict[str, Any]]:
        """è§£æAIå›å¤ä¸­çš„å·¥å…·è°ƒç”¨ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰"""
        import re
        import json
        
        tool_calls = []
        
        if self.DEBUG:
            print(f"[DEBUG] å¼€å§‹è§£æå·¥å…·è°ƒç”¨ï¼Œå†…å®¹é•¿åº¦: {len(content)}")
        
        # å°è¯•å¤šç§JSONæ ¼å¼
        json_patterns = [
            r'\{"tools":\s*\[.*?\]\}',        # {"tools": [...]}
            r'\{"tool_calls":\s*\[.*?\]\}',   # {"tool_calls": [...]}
            r'\{"actions":\s*\[.*?\]\}',      # {"actions": [...]}
            r'```json\n.*?\n```',             # ```json ... ```
            r'```\n.*?\n```',                 # ``` ... ``` (æ— jsonæ ‡è®°)
        ]
        
        for pattern_idx, pattern in enumerate(json_patterns):
            try:
                match = re.search(pattern, content, re.DOTALL)
                if match:
                    json_str = match.group(0)
                    
                    if self.DEBUG:
                        print(f"[DEBUG] æ‰¾åˆ°æ¨¡å¼ {pattern_idx}: {pattern}")
                        print(f"[DEBUG] åŒ¹é…åˆ°çš„JSONå­—ç¬¦ä¸²: {json_str[:200]}...")
                    
                    # æ¸…ç†JSONå­—ç¬¦ä¸²
                    json_str = json_str.replace('```json', '').replace('```', '').strip()
                    data = json.loads(json_str)
                    
                    # æå–å·¥å…·è°ƒç”¨
                    if "tools" in data and isinstance(data["tools"], list):
                        tool_calls = data["tools"]
                    elif "tool_calls" in data and isinstance(data["tool_calls"], list):
                        tool_calls = data["tool_calls"]
                    elif "actions" in data and isinstance(data["actions"], list):
                        tool_calls = data["actions"]
                    
                    if tool_calls:
                        if self.DEBUG:
                            print(f"âœ… æˆåŠŸè§£æå·¥å…·è°ƒç”¨ï¼ˆæ¨¡å¼ {pattern_idx}ï¼‰: {tool_calls}")
                        break
            except json.JSONDecodeError as e:
                if self.DEBUG:
                    print(f"[DEBUG] æ¨¡å¼ {pattern_idx} JSONè§£æå¤±è´¥: {e}")
                continue
            except KeyError as e:
                if self.DEBUG:
                    print(f"[DEBUG] æ¨¡å¼ {pattern_idx} ç¼ºå°‘é”®: {e}")
                continue
            except Exception as e:
                if self.DEBUG:
                    print(f"[DEBUG] æ¨¡å¼ {pattern_idx} è§£æå¤±è´¥: {e}")
                continue
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†æ ¼å¼ï¼Œå°è¯•æŸ¥æ‰¾ç®€å•çš„å·¥å…·è°ƒç”¨æŒ‡ç¤º
        if not tool_calls:
            # æŸ¥æ‰¾å¯èƒ½çš„å·¥å…·è°ƒç”¨æ¨¡å¼
            simple_patterns = [
                r'record_weight.*?\{.*?"weight".*?:.*?\d+',
                r'record_meal.*?\{.*?"meal_type".*?:.*?".*?"',
                r'record_exercise.*?\{.*?"exercise_type".*?:.*?".*?"',
                r'record_water.*?\{.*?"amount_ml".*?:.*?\d+',
            ]
            
            for pattern in simple_patterns:
                if re.search(pattern, content, re.IGNORECASE | re.DOTALL):
                    if self.DEBUG:
                        print(f"[DEBUG] æ‰¾åˆ°å¯èƒ½çš„å·¥å…·è°ƒç”¨æ¨¡å¼: {pattern}")
                    # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„è§£æé€»è¾‘
                    break
        
        # è§„èŒƒåŒ–å·¥å…·è°ƒç”¨æ ¼å¼ï¼šå°† "args" è½¬æ¢ä¸º "arguments"
        normalized_tool_calls = []
        for tool_call in tool_calls:
            normalized = tool_call.copy()
            
            # å¦‚æœä½¿ç”¨ "args" é”®ï¼Œé‡å‘½åä¸º "arguments"
            if "args" in normalized and "arguments" not in normalized:
                normalized["arguments"] = normalized.pop("args")
            
            # ç¡®ä¿æœ‰ "name" å’Œ "arguments" é”®
            if "name" in normalized and "arguments" in normalized:
                normalized_tool_calls.append(normalized)
            elif "tool" in normalized and "args" in normalized:
                # å¤„ç† {"tool": "record_weight", "args": {...}} æ ¼å¼
                normalized_tool_calls.append({
                    "name": normalized["tool"],
                    "arguments": normalized["args"]
                })
        
        if self.DEBUG and not normalized_tool_calls:
            print(f"âš ï¸ æœªæ‰¾åˆ°å·¥å…·è°ƒç”¨ï¼ŒAIå“åº”é¢„è§ˆ: {content[:300]}...")
        
        return normalized_tool_calls
    
    def _format_tool_results(self, results: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–å·¥å…·æ‰§è¡Œç»“æœ"""
        formatted = []
        for result in results:
            formatted.append(f"- {result.get('message', '')}")
        return "\n".join(formatted)
    
    def _build_structured_response(self, assistant_reply: str, tool_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ„å»ºç»“æ„åŒ–å“åº”ï¼ˆæ”¯æŒå¯Œåª’ä½“ï¼‰"""
        structured = {
            "type": "text",
            "content": assistant_reply,
            "actions": []
        }
        
        # æ ¹æ®å·¥å…·æ‰§è¡Œç»“æœæ·»åŠ å¿«æ·æ“ä½œ
        for result in tool_results:
            if result.get("success"):
                action_type = result.get("action_type")
                if action_type == "weight_recorded":
                    structured["actions"].append({
                        "type": "button",
                        "text": "æŸ¥çœ‹ä½“é‡è¶‹åŠ¿",
                        "action": "navigate",
                        "target": "weight.html"
                    })
                elif action_type == "meal_recorded":
                    structured["actions"].append({
                        "type": "button",
                        "text": "æŸ¥çœ‹ä»Šæ—¥é¥®é£Ÿ",
                        "action": "navigate",
                        "target": "meal.html"
                    })
                elif action_type == "exercise_recorded":
                    structured["actions"].append({
                        "type": "button",
                        "text": "æŸ¥çœ‹è¿åŠ¨è®°å½•",
                        "action": "navigate",
                        "target": "exercise.html"
                    })
        
        # å¦‚æœæœ‰å¿«æ·æ“ä½œï¼Œæ ‡è®°ä¸ºrichç±»å‹
        if structured["actions"]:
            structured["type"] = "rich"
        
        return structured

    async def _check_pending_tool_call(self, current_message: str, chat_history: List[Dict[str, str]]) -> Optional[Dict[str, Any]]:
        """æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„å·¥å…·è°ƒç”¨éœ€è¦ç»§ç»­"""
        # é¦–å…ˆæ£€æŸ¥å†…å­˜ä¸­æ˜¯å¦æœ‰å¾…å¤„ç†å·¥å…·è°ƒç”¨
        if self.memory:
            pending_info = await self.memory.get_tool_call_info()
            if pending_info:
                return pending_info.get("pending_tool_call")
                
        # å¦‚æœæ²¡æœ‰å†…å­˜ä¸­çš„å¾…å¤„ç†è°ƒç”¨ï¼Œå†æ£€æŸ¥å¯¹è¯å†å²
        if not chat_history or len(chat_history) < 2:
            return None
            
        # æ£€æŸ¥æœ€åä¸€æ¡åŠ©æ‰‹æ¶ˆæ¯æ˜¯å¦åœ¨è¯¢é—®é¢å¤–ä¿¡æ¯
        last_assistant_msg = None
        for i in range(len(chat_history)-1, -1, -1):
            if chat_history[i].get("role") == "assistant":
                last_assistant_msg = chat_history[i].get("content", "")
                break
        
        if not last_assistant_msg:
            return None
            
        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®é¥®å“ç±»å‹ã€è¿åŠ¨ç±»å‹ç­‰ä¿¡æ¯
        if any(keyword in last_assistant_msg for keyword in ["é¥®å“", "é¥®æ–™", "ä»€ä¹ˆæ°´", "è¿åŠ¨ç±»å‹", "ä»€ä¹ˆè¿åŠ¨", "ä»€ä¹ˆé£Ÿç‰©"]):
            # æ£€æŸ¥å½“å‰æ¶ˆæ¯æ˜¯å¦æä¾›äº†ç›¸å…³ç­”æ¡ˆ
            # é¥®å“ç±»å‹å…³é”®è¯ï¼ˆåŒ…å«å¸¸è§æ°´ç±»å’Œé¥®æ–™ï¼‰
            water_keywords = [
                "ç™½æ°´", "æ°´", "çŸ¿æ³‰æ°´", "çº¯å‡€æ°´", "å‡‰ç™½å¼€", "è‹æ‰“æ°´", "æ±½æ°´", 
                "å¯ä¹", "æœæ±", "èŒ¶æ°´", "å¥¶èŒ¶", "å’–å•¡", "é¥®æ–™", "ç‰›å¥¶", "é…¸å¥¶",
                "è¿åŠ¨é¥®æ–™", "åŠŸèƒ½é¥®æ–™", "æ±¤æ°´", "æ¸©æ°´", "çƒ­æ°´", "å†·æ°´", "å†°æ°´",
                "ç¢³é…¸é¥®æ–™", "èƒ½é‡é¥®æ–™", "é…’", "å•¤é…’", "çº¢é…’", "ç™½é…’"
            ]
            # è¿åŠ¨ç±»å‹å…³é”®è¯
            exercise_keywords = ["è·‘æ­¥", "æ•£æ­¥", "æ¸¸æ³³", "å¥èº«", "éª‘è½¦", "ç‘œä¼½", "ç¯®çƒ", "è¶³çƒ"]
            # é£Ÿç‰©å…³é”®è¯ï¼ˆç”¨äºé¤é£Ÿè®°å½•ï¼‰
            food_keywords = ["ç±³é¥­", "é¢", "è‚‰", "èœ", "æ°´æœ", "é›¶é£Ÿ", "æ±¤", "ç²¥", "é¢åŒ…"]
            
            # åˆå¹¶æ‰€æœ‰å…³é”®è¯
            answer_keywords = water_keywords + exercise_keywords + food_keywords
            
            # åˆ¤æ–­æ˜¯å¦æ˜¯åˆç†çš„å›ç­”ï¼šè¦ä¹ˆåŒ…å«å…³é”®è¯ï¼Œè¦ä¹ˆæ˜¯ç®€çŸ­åˆç†çš„å›ç­”ï¼ˆ2-10ä¸ªå­—ç¬¦ï¼‰
            is_valid_answer = any(keyword in current_message.lower() for keyword in answer_keywords)
            is_short_answer = len(current_message.strip()) >= 2 and len(current_message.strip()) <= 15
            
            if is_valid_answer or is_short_answer:
                # æŸ¥æ‰¾å‰ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¸­çš„å·¥å…·è°ƒç”¨ä¿¡æ¯
                prev_user_msg = None
                for i in range(len(chat_history)-1, -1, -1):
                    if chat_history[i].get("role") == "user":
                        prev_user_msg = chat_history[i].get("content", "")
                        break
                
                if prev_user_msg and any(quantity in prev_user_msg for quantity in ["ml", "æ¯«å‡", "å‡", "æ¯"]):
                    # æå–é¥®æ°´é‡ä¿¡æ¯
                    import re
                    amount_ml = None
                    
                    # å°è¯•åŒ¹é… ml æˆ– æ¯«å‡
                    ml_match = re.search(r'(\d+)\s*(ml|æ¯«å‡)', prev_user_msg.lower())
                    if ml_match:
                        amount_ml = int(ml_match.group(1))
                    
                    # å°è¯•åŒ¹é… æ¯ï¼ˆå‡è®¾1æ¯ = 200mlï¼‰
                    if amount_ml is None:
                        cup_match = re.search(r'(\d+)\s*æ¯', prev_user_msg)
                        if cup_match:
                            cups = int(cup_match.group(1))
                            amount_ml = cups * 200
                    
                    # å°è¯•åŒ¹é… å‡ï¼ˆ1å‡ = 1000mlï¼‰
                    if amount_ml is None:
                        liter_match = re.search(r'(\d+)\s*å‡', prev_user_msg)
                        if liter_match:
                            liters = float(liter_match.group(1))
                            amount_ml = int(liters * 1000)
                    
                    # å°è¯•åŒ¹é…"ä¸¤æ¯"è¿™ç§ä¸­æ–‡è¡¨è¾¾
                    if amount_ml is None:
                        chinese_num_match = re.search(r'(ä¸€|ä¸¤|äºŒ|ä¸‰|å››|äº”|å…­|ä¸ƒ|å…«|ä¹|å)\s*æ¯', prev_user_msg)
                        if chinese_num_match:
                            chinese_num_map = {
                                'ä¸€': 1, 'ä¸¤': 2, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4,
                                'äº”': 5, 'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'å': 10
                            }
                            cups = chinese_num_map.get(chinese_num_match.group(1), 1)
                            amount_ml = cups * 200
                    
                    if amount_ml:
                        return {
                            "name": "record_water",
                            "arguments": {"amount_ml": amount_ml},
                            "original_message": prev_user_msg,
                            "question": last_assistant_msg,
                            "answer": current_message
                        }
        
        return None

    async def _need_more_info_for_tool_call(self, tool_call: Dict[str, Any], ai_content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´å¤šä¿¡æ¯æ‰èƒ½æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        if tool_call.get("name") == "record_water":
            # æ£€æŸ¥AIæ˜¯å¦åœ¨è¯¢é—®é¥®å“ç±»å‹
            return any(keyword in ai_content for keyword in ["é¥®å“", "é¥®æ–™", "ä»€ä¹ˆæ°´", "å–çš„æ˜¯ä»€ä¹ˆ"])
        elif tool_call.get("name") == "record_exercise":
            # æ£€æŸ¥AIæ˜¯å¦åœ¨è¯¢é—®è¿åŠ¨ç±»å‹
            return any(keyword in ai_content for keyword in ["è¿åŠ¨ç±»å‹", "ä»€ä¹ˆè¿åŠ¨", "å“ªç§è¿åŠ¨"])
        elif tool_call.get("name") == "record_meal":
            # æ£€æŸ¥AIæ˜¯å¦åœ¨è¯¢é—®é£Ÿç‰©è¯¦æƒ…
            return any(keyword in ai_content for keyword in ["ä»€ä¹ˆé£Ÿç‰©", "åƒäº†ä»€ä¹ˆ", "é£Ÿç‰©æè¿°"])
        
        return False

    async def _mark_pending_tool_call(self, tool_call: Dict[str, Any], ai_content: str):
        """æ ‡è®°å¾…å¤„ç†çš„å·¥å…·è°ƒç”¨"""
        if self.memory:
            # ä½¿ç”¨å†…å­˜ä¿å­˜å¾…å¤„ç†å·¥å…·è°ƒç”¨ä¿¡æ¯
            await self.memory.save_tool_call_info({
                "pending_tool_call": tool_call,
                "ai_content": ai_content,
                "timestamp": datetime.utcnow().isoformat()
            })

    async def _handle_pending_tool_call(self, pending_tool_call: Dict[str, Any], user_answer: str) -> Dict[str, Any]:
        """å¤„ç†å¾…å¤„ç†çš„å·¥å…·è°ƒç”¨"""
        try:
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            result = await execute_tool(
                pending_tool_call["name"],
                pending_tool_call["arguments"],
                self.user_id,
                self.db
            )

            # æ„å»ºå›å¤æ¶ˆæ¯
            if result.get("success"):
                reply_message = f"âœ… {result.get('message', 'è®°å½•æˆåŠŸï¼')} "
                if "water" in pending_tool_call["name"]:
                    reply_message += f"æ„Ÿè°¢ä½ å‘Šè¯‰æˆ‘å–çš„æ˜¯{user_answer}ï¼Œä¿æŒè‰¯å¥½çš„é¥®æ°´ä¹ æƒ¯å¯¹ä½“é‡ç®¡ç†å¾ˆé‡è¦ï¼ğŸ’§"
                else:
                    reply_message += "æ„Ÿè°¢ä½ çš„ä¿¡æ¯ï¼"
            else:
                reply_message = f"âŒ {result.get('message', 'è®°å½•å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚')}"

            # ä¿å­˜åˆ°è®°å¿† - æ³¨æ„ï¼šAIçš„é—®é¢˜å·²ç»åœ¨æ ‡è®°pendingæ—¶ä¿å­˜è¿‡äº†ï¼Œè¿™é‡Œåªä¿å­˜ç”¨æˆ·çš„å›ç­”å’ŒAIçš„å›å¤
            if self.memory:
                await self.memory.save_message("user", user_answer)
                await self.memory.save_message("assistant", reply_message)

            # æ¸…é™¤å¾…å¤„ç†æ ‡è®°
            await self._clear_pending_tool_call()

            return {
                "response": reply_message,
                "structured_response": {
                    "type": "text",
                    "content": reply_message,
                    "actions": []
                },
                "intermediate_steps": [pending_tool_call],
            }
            
        except Exception as e:
            error_reply = f"æŠ±æ­‰ï¼Œå¤„ç†è®°å½•æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
            return {
                "response": error_reply,
                "structured_response": {"type": "text", "content": error_reply, "actions": []},
                "error": str(e),
            }

    async def _clear_pending_tool_call(self):
        """æ¸…é™¤å¾…å¤„ç†å·¥å…·è°ƒç”¨æ ‡è®°"""
        if self.memory:
            await self.memory.clear_tool_call_info()

    async def _simple_reply(self, message: str) -> str:
        from services.ai_service import ai_service

        # æ„å»ºåŒ…å«è®°å¿†çš„æç¤º
        memory_context = ""
        if self.memory:
            # æ£€ç´¢ç›¸å…³è®°å¿†
            relevant_memories = await self.memory.search_memory(message, k=3)
            if relevant_memories:
                memory_context = "\n\nã€ç›¸å…³å†å²è®°å¿†ã€‘\n" + "\n".join([
                    f"- {m['document']}" for m in relevant_memories
                ])

        # è·å–å¯¹è¯å†å²
        chat_history = []
        if self.memory:
            chat_history = self.memory.get_chat_history()

        # æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
        conversation_context = self._build_conversation_context(chat_history)

        system_prompt = f"""ä½ æ˜¯{self.agent_name}ï¼Œç”¨æˆ·çš„ä½“é‡ç®¡ç†åŠ©æ‰‹ã€‚

ã€æœ€è¿‘å¯¹è¯ã€‘
{conversation_context}
{memory_context}

ã€å›å¤åŸåˆ™ã€‘
1. å¦‚æœå†å²å¯¹è¯ä¸­æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·ä¼˜å…ˆä½¿ç”¨è¿™äº›ä¿¡æ¯å›ç­”
2. ä¿æŒç®€æ´ã€å‹å¥½
3. å¦‚æœä¸çŸ¥é“ç­”æ¡ˆï¼Œå¯ä»¥è¯¢é—®ç”¨æˆ·
"""

        simplified_prompt = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": message}
        ]
        try:
            response = await ai_service.chat(simplified_prompt, max_tokens=500)
            if not response.error:
                return response.content
        except Exception as e:
            print(f"_simple_reply error: {e}")
        return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚"

    async def get_chat_history(self) -> List[Dict[str, str]]:
        if not self.memory:
            return []
        return self.memory.get_chat_history()

    async def clear_memory(self):
        if self.memory:
            await self.memory.clear()


class AgentFactory:
    _instances: Dict[int, SimpleAgent] = {}

    @classmethod
    async def get_agent(
        cls,
        user_id: int,
        db: AsyncSession,
        force_new: bool = False
    ) -> SimpleAgent:
        if force_new or user_id not in cls._instances:
            agent_config = await cls._get_agent_config(user_id, db)
            cls._instances[user_id] = SimpleAgent(
                user_id=user_id,
                db=db,
                agent_name=agent_config.get("name"),
                personality_type=agent_config.get("personality_type", "warm"),
                enable_memory=True,
                enable_midterm_memory=True
            )
        cls._instances[user_id].db = db
        return cls._instances[user_id]

    @classmethod
    async def _get_agent_config(
        cls,
        user_id: int,
        db: AsyncSession
    ) -> Dict[str, Any]:
        from models.database import AgentConfig
        result = await db.execute(
            select(AgentConfig).where(AgentConfig.user_id == user_id)
        )
        config = result.scalar_one_or_none()
        if config:
            return {
                "name": config.agent_name or "å°åŠ©",
                "personality_type": config.personality_type.value if config.personality_type else "warm",
            }
        return {"name": "å°åŠ©", "personality_type": "warm"}

    @classmethod
    async def close_agent(cls, user_id: int):
        if user_id in cls._instances:
            if cls._instances[user_id].memory:
                await cls._instances[user_id].memory.clear()
            del cls._instances[user_id]

    @classmethod
    async def close_all(cls):
        for agent in cls._instances.values():
            if agent.memory:
                await agent.memory.clear()
        cls._instances.clear()


async def get_agent(user_id: int, db: AsyncSession) -> SimpleAgent:
    return await AgentFactory.get_agent(user_id, db)


async def chat_with_agent(
    user_id: int,
    db: AsyncSession,
    message: str
) -> Dict[str, Any]:
    """ä½¿ç”¨å¸¦è®°å¿†çš„å¯¹è¯åŠŸèƒ½"""
    try:
        from services.ai_service import ai_service
        from services.user_profile_service import UserProfileService
        from services.langchain.memory import get_user_memory
        
        # 1. è·å–ç”¨æˆ·è®°å¿†
        memory = await get_user_memory(user_id, db)
        
        # 2. è·å–ç”¨æˆ·ç”»åƒæ•°æ®ï¼ˆç”¨äºç³»ç»Ÿæç¤ºï¼‰
        profile_data = await UserProfileService.get_complete_profile(user_id, db)
        
        # 3. è·å–å¯¹è¯å†å²ï¼ˆä»è®°å¿†ï¼‰
        chat_history = memory.get_chat_history()
        
        # 4. æ„å»ºå®Œæ•´çš„ç³»ç»Ÿæç¤ºï¼ˆä¸åŒ…å«å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œå¯¹è¯å†å²ä¼šä½œä¸ºç‹¬ç«‹æ¶ˆæ¯ï¼‰
        system_prompt = await UserProfileService.format_system_prompt(profile_data, "")
        
        # 5. æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [{"role": "system", "content": system_prompt}]
        
        # 6. æ·»åŠ å¯¹è¯å†å²ï¼ˆæœ€è¿‘5è½®å¯¹è¯ï¼‰
        if chat_history:
            # åªå–æœ€è¿‘5è½®å¯¹è¯ï¼ˆæ¯è½®åŒ…å«ç”¨æˆ·æ¶ˆæ¯å’ŒåŠ©æ‰‹æ¶ˆæ¯ï¼‰
            # æ³¨æ„ï¼šä¸è¦åŒ…å«å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼Œå› ä¸ºå®ƒä¼šè¢«å•ç‹¬æ·»åŠ 
            recent_history = chat_history[-10:]  # 10æ¡æ¶ˆæ¯ = 5è½®å¯¹è¯
            for msg in recent_history:
                role = msg.get("role", "")
                content = msg.get("content", "")
                # ä½¿ç”¨ OpenAI æ ¼å¼çš„è§’è‰²åç§°
                if role == "user":
                    messages.append({"role": "user", "content": content})
                elif role == "assistant":
                    messages.append({"role": "assistant", "content": content})
        
        # 7. æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": message})
        
        # 8. è°ƒç”¨AIæœåŠ¡
        response = await ai_service.chat(messages, max_tokens=500)
        if response.error:
            return {"response": "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚", "intermediate_steps": []}
        
        assistant_reply = response.content
        
        # 9. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯å’ŒåŠ©æ‰‹å›å¤åˆ°è®°å¿†ï¼ˆå¦‚æœå¤±è´¥ï¼Œåªè®°å½•é”™è¯¯ï¼Œä¸å½±å“ä¸»æµç¨‹ï¼‰
        try:
            await memory.save_message("user", message)
            await memory.save_message("assistant", assistant_reply)
        except Exception as mem_error:
            print(f"Memory save error (non-critical): {mem_error}")
            # ç»§ç»­æ‰§è¡Œï¼Œè®°å¿†ä¿å­˜å¤±è´¥ä¸å½±å“èŠå¤©åŠŸèƒ½
        
        return {"response": assistant_reply, "intermediate_steps": []}
        
    except Exception as e:
        print(f"Chat with agent error: {e}")
        # é™çº§åˆ°ç®€å•å›å¤ï¼ˆæ— è®°å¿†ï¼‰
        try:
            from services.ai_service import ai_service
            
            system_prompt = """ä½ æ˜¯ç”¨æˆ·çš„ä½“é‡ç®¡ç†åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·ç®¡ç†ä½“é‡ã€è®°å½•é¥®é£Ÿã€è¿åŠ¨å’Œç¡çœ ã€‚
è¯·ç”¨ç®€æ´ã€å‹å¥½çš„æ–¹å¼å›å¤ï¼Œæ¯æ¬¡å›å¤æ§åˆ¶åœ¨100å­—ä»¥å†…ã€‚"""
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": message}
            ]
            
            response = await ai_service.chat(messages, max_tokens=500)
            if response.error:
                return {"response": "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚", "intermediate_steps": []}
            
            return {"response": response.content, "intermediate_steps": []}
        except Exception as inner_e:
            print(f"Fallback AI Error: {inner_e}")
            return {"response": "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚", "intermediate_steps": []}
